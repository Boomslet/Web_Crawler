# Web_Crawler
A scalable, open-source webcrawler that writes website data to file while crawling each new webpage

# Installation
##### Clone this repository:
```
$ git clone https://github.com/Boomslet/Web_Crawler
```

# Usage
##### 1. Run controller.py



##### 2. Call crawl(threadcount) with desired number of threads:
```Python
>>> crawl(1)
```
##### 3. Enter base URL(s):
```Python
Enter base URL 1: https://github.com/
``` 
##### 4. Crawl!
```Python
Successfully crawled https://github.com/
Successfully crawled https://github.com/#start-of-content
Successfully crawled https://github.com/features
Successfully crawled https://github.com/business
Successfully crawled https://github.com/pricing
Successfully crawled https://github.com/dashboard
``` 
