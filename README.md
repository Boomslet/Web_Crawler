# Web_Crawler
A scalable, open-source webcrawler that writes website data to file while crawling each new webpage

# Installation
##### 1. Clone this repository:
```
$ git clone https://github.com/Boomslet/Web_Crawler
```

##### 2. Run controller.py


##### 3. Call crawl(threadcount) with desired number of threads:
```Python
>>> crawl(2)
```
##### 4. Enter your base URLs:
```Python
Enter base URL 1: https://github.com/
Enter base URL 2: https://github.com/Boomslet
```
